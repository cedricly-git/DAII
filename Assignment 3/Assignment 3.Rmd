---
title: "Assignment 3"
author: 
  - Simon Alain Roger Gerdolle 23-611-940
  - Leonardo Gonnelli 23-617-111
  - Cédric Ly 23-615-487
date: "2025-03-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Import packages
```{r}
library(readr)
library(ggplot2)
library(dplyr)
```

```{r}
df3 <- read_csv("distances_birthtown-1.csv")
View(df3)
skimr::skim(df3)
```

# Question 1a)

We have : 
$Y_{i,1} = \beta_0 + \beta_1X_i+u_i$, and $Z_i = 5X_i$

We want to estimate the following new regression : 
$Y_{i, 1} = \theta_0 + \theta_1Z_i+u_i$

We will compute the new estimation by doing a simple substitution :
$Y_{i,1} = \beta_0+\beta_1X_i+u_i = \beta_0 + \beta_1(\frac{Z_i}{5})+u_i = \beta_0 + (\frac{\beta_1}{5})Z_i+u_i$

From this, we see that $\hat{\theta}_0 = \hat{\beta}_0$ (the intercept doesn't change) and that $\hat{\theta}_1 = \frac{\hat{\beta}_1}{5}$

# Question 1b)

For this question, we want to show that:
$\hat{\gamma}_1 = \hat{\beta}_1+\hat{\alpha}_1$

We know the following:
$W_i = Y_{i,1}+Y_{i,2}$

As $Y_{i,1}$ and $Y_{i,2}$ are both dependent variables of $X_i$, and that their regression curves are linear, we can simply add all the parameters (as we were adding two linear functions). 
$W_i = Y_{i,1}+Y_{i,2} = (\beta_0 + \beta_1X_i+u_i)+(\alpha_0+\alpha_1X_i+v_i)$
$\Leftrightarrow W_i =\beta_0 + \alpha_0 + (\beta_1 + \alpha_1)X_i + u_i + v_i$ 

We set:
$\beta_0 + \alpha_0 = \gamma_0$,
$\beta_1 + \alpha_1 = \gamma_1$,
$u_i+v_i = e_i$

Substituting our $W_i$ expression with the parameters we just set, we get:
$W_i = \gamma_0 + \gamma_1Xi+e_i$

# Question 2i) 
```{r}
# Cleaning Data

# Check 'medicine' variable format
unique(df3['medicine'])

# Encode 'medicine' variable
df3 <- mutate(df3, medicine = ifelse(medicine == "Yes", 1, 0))


# Set missing values for income variables
df3 <- mutate(df3, income = ifelse(income == -9999999, NaN, income)) %>%
  mutate(income_parent1 = ifelse(income_parent1 == -9999999, NaN, income_parent1)) %>%
  mutate(income_parent2 = ifelse(income_parent2 == -9999999, NaN, income_parent2))


# Negative travel time
df3 <- mutate(df3, travel_time = ifelse(travel_time < 0, NaN, travel_time))                    


# Omit missing variables 
df_sample <- df3 |>
  na.omit()


# Summarize the data again
skimr:: skim(df_sample)

# create new variables
df_sample <- df_sample |>
  mutate(income_parents = income_parent1 + income_parent2,
         travel_sq = travel_time^2)
```

# Question 2ii)

We want to determine the medicine regression curve computed on the joint effect of travel_time and income_parents parameters, i.e. 
$$
medicine_i = \beta_0  + \beta_1 \cdot \texttt{travel_time}_i +\beta_2\cdot\texttt{income_parents}_i + u_i
$$

$\beta_0$ = intercept of the regression curve 

$\beta_1$ = coefficient on travel_time (the expected rate of change in medicine in a change of travel_time)

$\beta_2$ = coefficient on income_parents (the expected rate of change in medicine in a change of income_parents)

$\texttt{u}_i$ = the error term

# Question 2iii)
```{r}
joint_lm <- lm(data = df_sample, medicine ~ travel_time + income_parents)
summary(joint_lm)

income_parents_lm <- lm(data = df_sample, medicine ~ income_parents)
summary(income_parents_lm)
```

*Interpretation* :

Yes, the point estimates for income_parents differ between the two models. In the simple regression (medicine ~ income_parents), the coefficient is approximately 0.000079 and statistically significant. However, in the joint regression that also includes travel_time, the coefficient drops to 0.000012 and becomes statistically insignificant.

This suggests that the relationship observed in the simple regression may be confounded by the omission of a relevant variable: travel_time. If income_parents and travel_time are correlated, omitting travel_time can bias the estimated effect of income_parents, a classic case of omitted variable bias. Once travel_time is controlled for in the joint model, it likely captures part of the variation previously attributed to income_parents, leading to a much smaller and insignificant coefficient.

This indicates that parental income alone may not significantly influence the probability of working in medicine once geographic access (as captured by travel time) is taken into account.

# Question 2iv)
*Description of the test* :

To test whether income_parents is correlated with travel_time, we regress travel_time on income_parents. The null hypothesis  $H_0$ states that there is no correlation $(α_1=0)$ , while the alternative $H_1$ states $\alpha_1 \neq 0$.

After running the regression, we examine the coefficient of income_parents. If the p-value associated with the coefficient is less than 0.05, we reject the null hypothesis and conclude that there is a statistically significant correlation between the two variables.

If the p-value is greater than 0.05, we fail to reject the null and conclude that there is no strong statistical evidence of correlation. This result helps us understand whether multicollinearity might affect the interpretation of regression coefficients in our earlier models.

```{r}
# Test for correlation
correlation_test <- lm(travel_time ~ income_parents, data = df_sample)
summary(correlation_test)
```
*Interpretation* :

We test whether income_parents is correlated with travel_time using a linear regression:

$$
\texttt{travel_time}_i = \alpha_0  + \alpha_1 \cdot \texttt{income_parents}_i + u_i
$$
The null hypothesis :
$\texttt{H}_0 : \alpha_1 = 0$
implies no correlation. The alternative hypothesis 
$\texttt{H}_1 : \alpha_1 \neq 0$ 
implies a correlation exists.

From the regression output, the estimated coefficient for income_parents is -0.0122, with a p-value < 2e-16, indicating strong statistical significance. We reject the null hypothesis and conclude that there is a significant negative correlation between parental income and travel time.

This suggests that students from higher-income families tend to have shorter travel times, which may reflect greater access to transportation or closer proximity to medical institutions. This correlation helps explain why the effect of income_parents changed in the joint regression from part (iii), due to overlapping explanatory power with travel_time.